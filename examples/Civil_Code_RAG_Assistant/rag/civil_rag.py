"""
æ°‘æ³•å…¸ä¸“ç”¨RAGå¼•æ“
"""

import sys
from pathlib import Path
from typing import List, Dict, Any, Optional

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

try:
    from langchain_ollama import OllamaEmbeddings, OllamaLLM
    from langchain_chroma import Chroma
    from langchain_core.runnables import RunnablePassthrough
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.documents import Document
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·å…ˆå®‰è£…ä¾èµ–: pip install -r requirements_civil.txt")
    sys.exit(1)

# å¯¼å…¥ä¸“ç”¨é…ç½®å’ŒPrompt
from examples.Civil_Code_RAG_Assistant.configs.civil_config import (
    CIVIL_VECTOR_DB_DIR,
    EMBED_MODEL,
    LLM_MODEL,
    TOP_K,
    TEMPERATURE,
    MAX_TOKENS,
    RETRIEVAL_METHOD,
    MMR_DIVERSITY,
    SCORE_THRESHOLD,
    LEGAL_TERMS_MAPPING
)

from examples.Civil_Code_RAG_Assistant.prompts.civil_prompts import (
    get_prompt_template
)

class CivilCodeRAG:
    """æ°‘æ³•å…¸RAGç³»ç»Ÿ - å®Œå…¨å…¼å®¹ç‰ˆ"""
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self.embeddings = None
        self.vectorstore = None
        self.llm = None
        self.rag_chain = None
        self.initialized = False
        
        if self.verbose:
            print("ğŸ”§ åˆå§‹åŒ–æ°‘æ³•å…¸RAGç³»ç»Ÿ...")
    
    def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        if self.initialized:
            return
        
        # 1. åˆå§‹åŒ–Embeddings
        if self.verbose:
            print(f"   ğŸ¤– åŠ è½½Embeddingæ¨¡å‹: {EMBED_MODEL}")
        self.embeddings = OllamaEmbeddings(model=EMBED_MODEL)
        
        # 2. åŠ è½½å‘é‡æ•°æ®åº“
        if self.verbose:
            print(f"   ğŸ“š åŠ è½½å‘é‡æ•°æ®åº“: {CIVIL_VECTOR_DB_DIR}")
        try:
            self.vectorstore = Chroma(
                persist_directory=CIVIL_VECTOR_DB_DIR,
                embedding_function=self.embeddings,
                collection_name="civil_code_collection"
            )
            count = self.vectorstore._collection.count()
            if self.verbose:
                print(f"   âœ… åŠ è½½æˆåŠŸï¼ŒåŒ…å« {count} ä¸ªæ³•å¾‹æ¡æ–‡")
        except Exception as e:
            print(f"âŒ åŠ è½½å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            print("   è¯·å…ˆè¿è¡Œå…¥åº“ç¨‹åº: python processors/civil_ingest.py")
            raise
        
        # 3. é…ç½®æ£€ç´¢å™¨ - ä½¿ç”¨ Chroma çš„å†…ç½®æ–¹æ³•
        if self.verbose:
            print(f"   ğŸ” é…ç½®æ£€ç´¢å™¨")
        
        # 4. åˆå§‹åŒ–LLM
        if self.verbose:
            print(f"   âš–ï¸  åˆå§‹åŒ–æ³•å¾‹æ¨¡å‹: {LLM_MODEL}")
        self.llm = OllamaLLM(
            model=LLM_MODEL,
            temperature=TEMPERATURE,
            num_predict=MAX_TOKENS,
            top_p=0.9,
            repeat_penalty=1.1,
            num_ctx=4096,
            # stop=["ã€é‡è¦æç¤ºã€‘", "---"]  # æ·»åŠ æ˜ç¡®çš„åœæ­¢è¯
        )
        
        # 5. æ„å»ºRAG Chain
        self.rag_chain = self._build_rag_chain()
        
        self.initialized = True
        if self.verbose:
            print("âœ… æ°‘æ³•å…¸RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def _retrieve_documents(self, query: str) -> str:
        """æ£€ç´¢æ–‡æ¡£ï¼Œæ ¹æ®é…ç½®ä½¿ç”¨ä¸åŒæ–¹æ³•"""
        try:
            if RETRIEVAL_METHOD == "mmr":
                # MMRæ£€ç´¢
                docs = self.vectorstore.max_marginal_relevance_search(
                    query=query,
                    k=TOP_K,
                    fetch_k=TOP_K * 3,
                    lambda_mult=MMR_DIVERSITY
                )
            elif RETRIEVAL_METHOD == "similarity_score_threshold":
                # å¸¦ç›¸ä¼¼åº¦é˜ˆå€¼æ£€ç´¢
                docs_with_scores = self.vectorstore.similarity_search_with_score(
                    query=query,
                    k=TOP_K * 2
                )
                docs = []
                for doc, score in docs_with_scores:
                    if score >= SCORE_THRESHOLD:
                        docs.append(doc)
                    if len(docs) >= TOP_K:
                        break
            else:
                # é»˜è®¤ç›¸ä¼¼åº¦æ£€ç´¢
                docs = self.vectorstore.similarity_search(
                    query=query,
                    k=TOP_K
                )
            
            # åˆå¹¶æ–‡æ¡£å†…å®¹
            if not docs:
                return "æœªæ‰¾åˆ°ç›¸å…³æ³•å¾‹æ¡æ–‡ã€‚"
            
            context_parts = []
            for i, doc in enumerate(docs):
                # æ·»åŠ æ³•æ¡å·å’Œå†…å®¹
                article_num = doc.metadata.get('article_number', f'ç¬¬{i+1}æ¡')
                content = doc.page_content.strip()
                context_parts.append(f"ã€{article_num}ã€‘{content}")
            
            return "\n\n".join(context_parts)
            
        except Exception as e:
            print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
            return "æ£€ç´¢æ³•å¾‹æ¡æ–‡æ—¶å‡ºç°é”™è¯¯ã€‚"
    
    def _build_rag_chain(self, prompt_mode: str = "detailed"):
        """æ„å»ºRAG Chain - ç®€å•ç›´æ¥çš„æ–¹å¼"""
        prompt_template = get_prompt_template(prompt_mode)
        
        def rag_pipeline(question: str) -> str:
            """å®Œæ•´çš„RAGæµæ°´çº¿"""
            # 1. æ£€ç´¢
            context = self._retrieve_documents(question)
            
            # 2. æ„å»ºæç¤ºè¯
            prompt = prompt_template.format(context=context, question=question)
            
            # 3. ç”Ÿæˆå›ç­”
            return self.llm.invoke(prompt)
        
        return rag_pipeline
    
    def query(self, question: str, stream: bool = False):
        """æŸ¥è¯¢æ°‘æ³•å…¸"""
        if not self.initialized:
            self.initialize()
        
        if self.verbose:
            print(f"â“ é—®é¢˜: {question}")
            print("ğŸ” æ£€ç´¢ç›¸å…³æ³•æ¡...")
        
        try:
            # ç®€å•ç‰ˆæœ¬ä¸æ”¯æŒæµå¼ï¼Œå¯ä»¥åç»­æ·»åŠ 
            response = self.rag_chain(question)
            yield response
            
        except Exception as e:
            error_msg = f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}"
            print(error_msg)
            yield error_msg
    
    def get_retrieved_documents(self, query: str, k: Optional[int] = None) -> List[Document]:
        """è·å–æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        if not self.initialized:
            self.initialize()
        
        k = k or TOP_K
        try:
            docs = self.vectorstore.similarity_search(query, k=k)
            return docs
        except Exception as e:
            print(f"âŒ è·å–æ£€ç´¢æ–‡æ¡£å¤±è´¥: {e}")
            return []
    
    def get_system_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        if not self.initialized:
            return {"status": "æœªåˆå§‹åŒ–"}
        
        count = self.vectorstore._collection.count() if self.vectorstore else 0
        
        return {
            "status": "è¿è¡Œä¸­",
            "vector_count": count,
            "embedding_model": EMBED_MODEL,
            "llm_model": LLM_MODEL,
            "retrieval_method": RETRIEVAL_METHOD,
            "top_k": TOP_K,
            "temperature": TEMPERATURE
        }
    
    # åœ¨ CivilCodeRAG ç±»ä¸­æ·»åŠ ä»¥ä¸‹æ–¹æ³•
    def query_simple(self, question: str) -> str:
        """éæµå¼æŸ¥è¯¢ï¼Œç›´æ¥è¿”å›å®Œæ•´ç­”æ¡ˆ"""
        if not self.initialized:
            self.initialize()
        
        if self.verbose:
            print(f"â“ é—®é¢˜: {question}")
            print("ğŸ” æ£€ç´¢ç›¸å…³æ³•æ¡...")
        
        try:
            # æ„å»ºå®Œæ•´æç¤ºè¯
            context = self._retrieve_documents(question)
            prompt = self._build_simple_prompt(context, question)
            
            # è°ƒç”¨LLM
            response = self.llm.invoke(prompt)
            return response
            
        except Exception as e:
            return f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}"
        
    def _build_simple_prompt(self, context: str, question: str) -> str:
        """æ„å»ºç®€å•æç¤ºè¯"""
        return f"""è¯·åŸºäºä»¥ä¸‹æ°‘æ³•å…¸æ¡æ–‡å›ç­”é—®é¢˜ï¼š
    
    ã€ç›¸å…³æ³•å¾‹æ¡æ–‡ã€‘
    {context}
    
    ã€ç”¨æˆ·é—®é¢˜ã€‘
    {question}
    
    è¯·ä»¥ä¸“ä¸šæ³•å¾‹é¡¾é—®çš„èº«ä»½å›ç­”ï¼Œè¦æ±‚ï¼š
    1. å¼•ç”¨å…·ä½“æ³•æ¡å·
    2. è§£é‡Šæ³•å¾‹å«ä¹‰
    3. ç»™å‡ºå®è·µå»ºè®®
    4. æœ€åæ³¨æ˜"æ³¨ï¼šæœ¬å›ç­”ä»…ä¾›å‚è€ƒï¼Œå…·ä½“æ¡ˆä»¶è¯·å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆ"
    
    ã€å›ç­”ã€‘ï¼š
    """
    

# å…¼å®¹åŸæœ‰æ¥å£
def build_civil_code_chain(streaming: bool = False):
    """åˆ›å»ºæ°‘æ³•å…¸RAGé“¾"""
    rag = CivilCodeRAG(verbose=True)
    rag.initialize()
    
    def query_function(question: str):
        return next(rag.query(question, stream=False))
    
    return query_function